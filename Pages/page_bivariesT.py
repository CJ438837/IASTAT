import streamlit as st

def app():
    # --- Titre principal ---
    st.title("ğŸ“Š Tests BivariÃ©s")
    st.markdown("---")

    # --- Objectif ---
    st.subheader("ğŸ¯ Objectif")
    st.markdown("""
    Les tests bivariÃ©s permettent dâ€™explorer les **relations entre deux variables**.  
    Selon les types de variables (numÃ©rique, catÃ©gorielle, binaire) et les propriÃ©tÃ©s des donnÃ©es (normalitÃ©, variance), diffÃ©rents tests statistiques sont utilisÃ©s.
    
    Ils servent Ã  :
    - Identifier les corrÃ©lations ou associations significatives
    - Mesurer la force de ces relations via **effect sizes** et CramÃ©râ€™s V
    - Fournir des intervalles de confiance pour les corrÃ©lations
    - Orienter lâ€™analyse multivariÃ©e ou la modÃ©lisation prÃ©dictive
    """)

    st.markdown("---")

    # --- Variables numÃ©riques vs numÃ©riques ---
    st.subheader("ğŸ”· Variables numÃ©riques vs numÃ©riques")
    st.markdown("""
    - **CorrÃ©lation de Pearson** : si les deux variables sont **normales**  
    - **CorrÃ©lation de Spearman** : si lâ€™une ou les deux variables ne sont pas normales  
    - **Kendall Tau** : robuste aux valeurs aberrantes  
    - **Bootstrap IC** : intervalles de confiance pour les corrÃ©lations  
    - **Pente robuste Theil-Sen** : estimation de la tendance linÃ©aire robuste  
    - **Visualisation** : scatter plot avec ligne de tendance  
    - **InterprÃ©tation** : coefficient entre -1 et 1, proche de 0 = pas de relation
    """)

    st.markdown("---")

    # --- Variables numÃ©riques vs catÃ©gorielles ---
    st.subheader("ğŸ”· Variables numÃ©riques vs catÃ©gorielles")
    st.markdown("""
    - **T-test** (2 groupes) ou **ANOVA** (â‰¥3 groupes) : si normalitÃ© et homogÃ©nÃ©itÃ© des variances  
    - **T-test appariÃ©** ou **Wilcoxon** : si donnÃ©es appariÃ©es  
    - **Mann-Whitney / Kruskal-Wallis** : si non-normalitÃ©  
    - **Taille dâ€™effet** : Cohenâ€™s d (2 groupes), etaÂ² (â‰¥3 groupes), rank-biserial pour tests non paramÃ©triques  
    - **Visualisation** : boxplot, violin plot  
    - **InterprÃ©tation** : p-value < 0.05 â†’ diffÃ©rence statistiquement significative, taille dâ€™effet interprÃ©tÃ©e en plus de la p-value
    """)

    st.markdown("---")

    # --- Variables catÃ©gorielles vs catÃ©gorielles ---
    st.subheader("ğŸ”· Variables catÃ©gorielles vs catÃ©gorielles")
    st.markdown("""
    - **Test du ChiÂ²** : si effectifs suffisants  
    - **Test exact de Fisher** : si effectifs faibles ou tableau 2x2  
    - **CramÃ©râ€™s V** : mesure de la force de lâ€™association (0 = pas dâ€™association, 1 = association parfaite)  
    - **Visualisation** : heatmap (tableau de contingence)  
    - **InterprÃ©tation** : p-value < 0.05 â†’ association significative, CramÃ©râ€™s V dÃ©crit la force de lâ€™association
    """)

    st.markdown("---")

    # --- Bonnes pratiques ---
    st.subheader("ğŸ’¡ Bonnes pratiques")
    st.markdown("""
    - VÃ©rifiez la normalitÃ© et lâ€™homogÃ©nÃ©itÃ© avant dâ€™appliquer des tests paramÃ©triques  
    - Toujours reprÃ©senter graphiquement les relations pour mieux interprÃ©ter  
    - Tenir compte de la taille dâ€™effet et des intervalles de confiance, pas seulement de la p-value  
    - Pour les variables catÃ©gorielles avec modalitÃ©s rares, envisagez un regroupement  
    - Utiliser la correction FDR (p-value corrigÃ©e) lorsquâ€™on teste plusieurs relations simultanÃ©ment
    """)

    st.markdown("---")

    # --- Conclusion ---
    st.subheader("ğŸ“ Conclusion")
    st.markdown("""
    Les tests bivariÃ©s permettent de dÃ©tecter **significativitÃ©, force et robustesse des relations**.  
    Ils sont essentiels pour orienter lâ€™analyse multivariÃ©e ou la modÃ©lisation prÃ©dictive, et pour comprendre les mÃ©canismes sous-jacents dans vos donnÃ©es.
    """)

    st.markdown("---")
    st.markdown("Â© 2025 Corvus Analytics - Tous droits rÃ©servÃ©s")
